{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Torch tutorial",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Torch Operations"
      ],
      "metadata": {
        "id": "xLHWX6rKdonh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AmK5XiJdlGm",
        "outputId": "43390ac5-2b15-4b0f-fa91-2cc25b7ee8ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import torch\n",
        "x=torch.empty(2,3,3)                # fill with garbage values\n",
        "x=torch.rand(2,2)                   # fill with random values\n",
        "x=torch.ones(3,3,dtype=torch.int)   # fill with ones\n",
        "x=torch.zeros(3,3,dtype=torch.float16) # fill with zeros\n",
        "x=torch.tensor([1,3,4])             # fill with constants\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# element wise operation\n",
        "\n",
        "#available operations: add_,mul_,div_\n",
        "x=x+x\n",
        "x=torch.add(x,x)\n",
        "x.add_(x)  #inplace addition\n",
        "\n",
        "\n",
        "#slicing\n",
        "x=torch.rand(2,4,4)\n",
        "print(x[:,1,1:3])     #get all rows, only first column\n",
        "print(x[0,0,0].item()) #NOTE: item() can only be used to return value of one item in tensor\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSiLVvyzdym5",
        "outputId": "409d2ffe-0764-4a16-f45d-64c9e520209e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3038, 0.5920],\n",
            "        [0.4330, 0.0238]])\n",
            "0.3948076367378235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "a=torch.ones(5)\n",
        "print(a)"
      ],
      "metadata": {
        "id": "cAH5XQm9fb4u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "179d1d2a-665d-4139-8528-344103026143"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autograd package"
      ],
      "metadata": {
        "id": "jCRCNKBUafd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "x=torch.randn(3,requires_grad=True)\n",
        "print(x)\n",
        "y=x+2\n",
        "v=torch.tensor([0.1,1,0.001],dtype=torch.float32)\n",
        "y=y*y+2\n",
        "print(y)\n",
        "y.backward(v)\n",
        "print(x.grad)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7bMS6DZZ7Rk",
        "outputId": "d348dce1-0efb-4005-aa4a-424c5df956c6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.4631,  1.4813,  1.9980], requires_grad=True)\n",
            "tensor([ 4.3621, 14.1197, 17.9839], grad_fn=<AddBackward0>)\n",
            "tensor([0.3074, 6.9627, 0.0080])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#remove gradient tracking:\n",
        "'''\n",
        "x.requires_grad_(False)\n",
        "x.detach()\n",
        "with torch.no_grad():\n",
        "'''\n",
        "weights=torch.ones(4,requires_grad=True)\n",
        "for epoch in range(4):\n",
        "  model_output=(weights*3).sum()\n",
        "  model_output.backward()\n",
        "  print(weights.grad)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yzdtrZ1aoAL",
        "outputId": "2c953999-0ea0-4f9b-dfef-3e2c7a470cdd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "tensor([6., 6., 6., 6.])\n",
            "tensor([9., 9., 9., 9.])\n",
            "tensor([12., 12., 12., 12.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Back Propogation"
      ],
      "metadata": {
        "id": "DFmY-55PeXoK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "x=torch.tensor(1.0)\n",
        "y=torch.tensor(2.0)\n",
        "w=torch.tensor(1.0,requires_grad=True)\n",
        "for epoch in range(4):\n",
        "  print(w)\n",
        "  # forward pass and compute loss\n",
        "  y_pred=w*x\n",
        "  loss=(y_pred-y)**2\n",
        "  print('loss: ',loss)\n",
        "  print('gradient of w:', w.grad)\n",
        "\n",
        "  #backward pass\n",
        "  loss.backward()\n",
        "  print('new gradient of w: ',w.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWQ9jAKxeTS4",
        "outputId": "cec9ddbe-d8d0-4b4a-d62d-ba523ca2268d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1., requires_grad=True)\n",
            "loss:  tensor(1., grad_fn=<PowBackward0>)\n",
            "gradient of w: None\n",
            "new gradient of w:  tensor(-2.)\n",
            "tensor(1., requires_grad=True)\n",
            "loss:  tensor(1., grad_fn=<PowBackward0>)\n",
            "gradient of w: tensor(-2.)\n",
            "new gradient of w:  tensor(-4.)\n",
            "tensor(1., requires_grad=True)\n",
            "loss:  tensor(1., grad_fn=<PowBackward0>)\n",
            "gradient of w: tensor(-4.)\n",
            "new gradient of w:  tensor(-6.)\n",
            "tensor(1., requires_grad=True)\n",
            "loss:  tensor(1., grad_fn=<PowBackward0>)\n",
            "gradient of w: tensor(-6.)\n",
            "new gradient of w:  tensor(-8.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient Descent"
      ],
      "metadata": {
        "id": "9xElfQPwigbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x=np.array([1,2,3,4],dtype=np.float32)\n",
        "y=np.array([2,4,6,8],dtype=np.float32)\n",
        "w=100\n",
        "\n",
        "#model prediction\n",
        "\n",
        "def forward(x):\n",
        "  return w*x\n",
        "\n",
        "\n",
        "#loss\n",
        "def loss(y,y_pred):\n",
        "  return ((y_pred-y)**2).mean()\n",
        "\n",
        "#gradient\n",
        "def gradient(x,y,y_pred):\n",
        "  return np.dot(2*x,y_pred-y).mean()\n",
        "\n",
        "print(f'prediction before training f(5): {forward(5):.3f}')\n",
        "\n",
        "#Training\n",
        "lr=0.01\n",
        "iter=20\n",
        "\n",
        "for epoch in range(iter):\n",
        "  y_pred=forward(x)\n",
        "  l=loss(y,y_pred)\n",
        "  dw=gradient(x,y,y_pred)\n",
        "\n",
        "  #update weights\n",
        "\n",
        "  w-=lr*dw\n",
        "  if epoch % 1 ==0:\n",
        "    print(f'epoch: {epoch+1}; w = {w:.3f}; loss = {l:.8f}')\n",
        "    \n",
        "  print(f'f(5): {forward(5):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5CFW3ERhfS_",
        "outputId": "268e70c8-4f1f-467a-e6dc-24f8d4be0ae8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction before training f(5): 500.000\n",
            "epoch: 1; w = 41.200; loss = 72030.00000000\n",
            "f(5): 206.000\n",
            "epoch: 2; w = 17.680; loss = 11524.80078125\n",
            "f(5): 88.400\n",
            "epoch: 3; w = 8.272; loss = 1843.96801758\n",
            "f(5): 41.360\n",
            "epoch: 4; w = 4.509; loss = 295.03491211\n",
            "f(5): 22.544\n",
            "epoch: 5; w = 3.004; loss = 47.20556259\n",
            "f(5): 15.018\n",
            "epoch: 6; w = 2.401; loss = 7.55289316\n",
            "f(5): 12.007\n",
            "epoch: 7; w = 2.161; loss = 1.20846248\n",
            "f(5): 10.803\n",
            "epoch: 8; w = 2.064; loss = 0.19335407\n",
            "f(5): 10.321\n",
            "epoch: 9; w = 2.026; loss = 0.03093682\n",
            "f(5): 10.128\n",
            "epoch: 10; w = 2.010; loss = 0.00494985\n",
            "f(5): 10.051\n",
            "epoch: 11; w = 2.004; loss = 0.00079199\n",
            "f(5): 10.021\n",
            "epoch: 12; w = 2.002; loss = 0.00012671\n",
            "f(5): 10.008\n",
            "epoch: 13; w = 2.001; loss = 0.00002027\n",
            "f(5): 10.003\n",
            "epoch: 14; w = 2.000; loss = 0.00000324\n",
            "f(5): 10.001\n",
            "epoch: 15; w = 2.000; loss = 0.00000052\n",
            "f(5): 10.001\n",
            "epoch: 16; w = 2.000; loss = 0.00000008\n",
            "f(5): 10.000\n",
            "epoch: 17; w = 2.000; loss = 0.00000001\n",
            "f(5): 10.000\n",
            "epoch: 18; w = 2.000; loss = 0.00000000\n",
            "f(5): 10.000\n",
            "epoch: 19; w = 2.000; loss = 0.00000000\n",
            "f(5): 10.000\n",
            "epoch: 20; w = 2.000; loss = 0.00000000\n",
            "f(5): 10.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "x=torch.tensor([1,2,3,4],dtype=torch.float32)\n",
        "y=torch.tensor([2,4,6,8],dtype=torch.float32)\n",
        "w=torch.tensor(0.0,requires_grad=True,dtype=torch.float32)\n",
        "\n",
        "#model prediction\n",
        "\n",
        "def forward(x):\n",
        "  return w*x\n",
        "\n",
        "\n",
        "#loss\n",
        "def loss(y,y_pred):\n",
        "  return ((y_pred-y)**2).mean()\n",
        "\n",
        "#gradient\n",
        "def gradient(x,y,y_pred):\n",
        "  return np.dot(2*x,y_pred-y).mean()\n",
        "\n",
        "print(f'prediction before training f(5): {forward(5):.3f}')\n",
        "\n",
        "#Training\n",
        "lr=0.01\n",
        "iter=20\n",
        "\n",
        "for epoch in range(iter):\n",
        "  y_pred=forward(x)\n",
        "  l=loss(y,y_pred)\n",
        "  l.backward()\n",
        "\n",
        "  #update weights\n",
        "  with torch.no_grad():\n",
        "    w-=lr*w.grad\n",
        "\n",
        "  w.grad.zero_()\n",
        "  if epoch % 2 ==0:\n",
        "    print(f'epoch: {epoch+1}; w = {w:.3f}; loss = {l:.8f}')\n",
        "    \n",
        "  print(f'f(5): {forward(5):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qOx8Zp2k0P2",
        "outputId": "1c6129a7-b185-42ce-8459-446a677851da"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction before training f(5): 0.000\n",
            "epoch: 1; w = 0.300; loss = 30.00000000\n",
            "f(5): 1.500\n",
            "f(5): 2.775\n",
            "epoch: 3; w = 0.772; loss = 15.66018772\n",
            "f(5): 3.859\n",
            "f(5): 4.780\n",
            "epoch: 5; w = 1.113; loss = 8.17471695\n",
            "f(5): 5.563\n",
            "f(5): 6.229\n",
            "epoch: 7; w = 1.359; loss = 4.26725292\n",
            "f(5): 6.794\n",
            "f(5): 7.275\n",
            "epoch: 9; w = 1.537; loss = 2.22753215\n",
            "f(5): 7.684\n",
            "f(5): 8.031\n",
            "epoch: 11; w = 1.665; loss = 1.16278565\n",
            "f(5): 8.327\n",
            "f(5): 8.578\n",
            "epoch: 13; w = 1.758; loss = 0.60698116\n",
            "f(5): 8.791\n",
            "f(5): 8.972\n",
            "epoch: 15; w = 1.825; loss = 0.31684780\n",
            "f(5): 9.126\n",
            "f(5): 9.257\n",
            "epoch: 17; w = 1.874; loss = 0.16539653\n",
            "f(5): 9.369\n",
            "f(5): 9.464\n",
            "epoch: 19; w = 1.909; loss = 0.08633806\n",
            "f(5): 9.544\n",
            "f(5): 9.612\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training pipeline"
      ],
      "metadata": {
        "id": "2YwcMqdKmaZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "#input\n",
        "x=torch.tensor([[1],[2],[3],[4]],dtype=torch.float32)\n",
        "\n",
        "#expected output\n",
        "y=torch.tensor([[2],[4],[6],[8]],dtype=torch.float32)\n",
        "\n",
        "#test input\n",
        "test=torch.tensor([5],dtype=torch.float32)\n",
        "\n",
        "n_samples,n_features=x.shape\n",
        "input_size=n_features\n",
        "output_size=n_features\n",
        "\n",
        "\n",
        "#model\n",
        "class LinearRegression(nn.Module):\n",
        "  def __init__(self,input_dim,output_dim):\n",
        "    super(LinearRegression,self).__init__()\n",
        "    self.lin=nn.Linear(input_dim,output_dim)\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.lin(x)\n",
        "  \n",
        "model=LinearRegression(input_size,output_size)\n",
        "\n",
        "\n",
        "#loss function to calculate difference between predicted and current\n",
        "loss=nn.MSELoss()\n",
        "\n",
        "#optimiser to minimise given loss on model by changing model weights\n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=lr)\n",
        "\n",
        "\n",
        "print(f'prediction before training f(5): {forward(test).item():.3f}')\n",
        "\n",
        "#Training\n",
        "lr=0.01\n",
        "iter=20\n",
        "\n",
        "\n",
        "for epoch in range(iter):\n",
        "  y_pred=model.forward(x)\n",
        "  l=loss(y,y_pred)\n",
        "  l.backward()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "  if epoch % 2 ==0:\n",
        "    [w,b]=model.parameters()\n",
        "\n",
        "    print(f'epoch: {epoch+1}; w = {w[0][0]}; loss = {l:.8f}')\n",
        "    print(f'f(5): {forward(test).item():.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diLaKuvQmLQl",
        "outputId": "e7ef8980-00b4-46da-e42b-319382e7069f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction before training f(5): 14.797\n",
            "epoch: 1; w = 0.06583143025636673; loss = 38.52408600\n",
            "f(5): 0.329\n",
            "epoch: 3; w = 0.585242748260498; loss = 18.59125519\n",
            "f(5): 2.926\n",
            "epoch: 5; w = 0.9460858106613159; loss = 8.99372101\n",
            "f(5): 4.730\n",
            "epoch: 7; w = 1.1968990564346313; loss = 4.37230921\n",
            "f(5): 5.984\n",
            "epoch: 9; w = 1.3713624477386475; loss = 2.14674592\n",
            "f(5): 6.857\n",
            "epoch: 11; w = 1.4928457736968994; loss = 1.07471204\n",
            "f(5): 7.464\n",
            "epoch: 13; w = 1.5775647163391113; loss = 0.55807149\n",
            "f(5): 7.888\n",
            "epoch: 15; w = 1.6367710828781128; loss = 0.30884147\n",
            "f(5): 8.184\n",
            "epoch: 17; w = 1.6782723665237427; loss = 0.18836650\n",
            "f(5): 8.391\n",
            "epoch: 19; w = 1.7074857950210571; loss = 0.12988871\n",
            "f(5): 8.537\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "#input\n",
        "x=torch.tensor([[1],[2],[3],[4]],dtype=torch.float32)\n",
        "\n",
        "#expected output\n",
        "y=torch.tensor([[2],[4],[6],[8]],dtype=torch.float32)\n",
        "\n",
        "#test input\n",
        "test=torch.tensor([5],dtype=torch.float32)\n",
        "\n",
        "n_samples,n_features=x.shape\n",
        "input_size=n_features\n",
        "output_size=n_features\n",
        "\n",
        "\n",
        "#model\n",
        "class LinearRegression(nn.Module):\n",
        "  def __init__(self,input_dim,output_dim):\n",
        "    super(LinearRegression,self).__init__()\n",
        "    self.lin=nn.Linear(input_dim,output_dim)\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.lin(x)\n",
        "  \n",
        "model=LinearRegression(input_size,output_size)\n",
        "\n",
        "\n",
        "#loss function to calculate difference between predicted and current\n",
        "loss=nn.MSELoss()\n",
        "\n",
        "#optimiser to minimise given loss on model by changing model weights\n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=lr)\n",
        "\n",
        "\n",
        "print(f'prediction before training f(5): {forward(test).item():.3f}')\n",
        "\n",
        "#Training\n",
        "lr=0.01\n",
        "iter=20\n",
        "\n",
        "\n",
        "for epoch in range(iter):\n",
        "  y_pred=model.forward(x)\n",
        "  l=loss(y,y_pred)\n",
        "  l.backward()\n",
        "  optimizer.step()\n",
        "  if epoch % 2 ==0:\n",
        "    [w,b]=model.parameters()\n",
        "\n",
        "    print(f'epoch: {epoch+1}; w = {w[0][0]}; loss = {l:.8f}')\n",
        "    print(f'f(5): {forward(test).item():.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcGjdGN9px9I",
        "outputId": "79e29276-1d60-4cc4-a450-b39d60ac5e68"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction before training f(5): 12.542\n",
            "epoch: 1; w = -0.17460355162620544; loss = 39.85884857\n",
            "f(5): -0.873\n",
            "epoch: 3; w = 1.2750879526138306; loss = 11.27946281\n",
            "f(5): 6.375\n",
            "epoch: 5; w = 2.9052915573120117; loss = 3.46660089\n",
            "f(5): 14.526\n",
            "epoch: 7; w = 3.6801609992980957; loss = 33.19767380\n",
            "f(5): 18.401\n",
            "epoch: 9; w = 3.1146790981292725; loss = 36.48851013\n",
            "f(5): 15.573\n",
            "epoch: 11; w = 1.5850011110305786; loss = 6.20999908\n",
            "f(5): 7.925\n",
            "epoch: 13; w = 0.08749580383300781; loss = 7.42359161\n",
            "f(5): 0.437\n",
            "epoch: 15; w = -0.39926877617836; loss = 37.45241547\n",
            "f(5): -1.996\n",
            "epoch: 17; w = 0.45882153511047363; loss = 31.64179230\n",
            "f(5): 2.294\n",
            "epoch: 19; w = 2.137280225753784; loss = 2.41944838\n",
            "f(5): 10.686\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# linear regression"
      ],
      "metadata": {
        "id": "4NhD4XYM8ttP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x_numpy,y_numpy=datasets.make_regression(n_samples=100,n_features=1,noise=20,random_state=1)\n",
        "X=torch.from_numpy(x_numpy.astype(np.float32))\n",
        "Y=torch.from_numpy(y_numpy.astype(np.float32))\n",
        "print(X.shape,Y.shape)\n",
        "Y=Y.view(Y.shape[0],1)\n",
        "\n",
        "n_samples,n_features=X.shape\n",
        "\n",
        "input_size=1\n",
        "output_size=1\n",
        "\n",
        "#model\n",
        "model=nn.Linear(input_size,output_size)\n",
        "\n",
        "#loss and optimier\n",
        "\n",
        "lr=0.01\n",
        "criterion=nn.MSELoss()\n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=lr)\n",
        "\n",
        "#training loop\n",
        "\n",
        "for epoch in range(1000):\n",
        "  y_pred=model(X)\n",
        "  loss=criterion(Y,y_pred)\n",
        "  loss.backward()\n",
        "\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if(epoch%5==0):\n",
        "    print(f'epoch: {epoch+1}; loss: {loss}')\n",
        "\n",
        "\n",
        "#plot\n",
        "\n",
        "predicted=model(X).detach().numpy()\n",
        "plt.plot(X.numpy(),predicted,'r')\n",
        "plt.plot(X.numpy(),Y.numpy(),'bo')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "cPkSEldTtS62",
        "outputId": "d5d9cd5d-7fa9-484b-bbe3-708bbd9d4a77"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 2]) torch.Size([100])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-e39a2ffa6edc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m   \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m   \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (100x2 and 1x1)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic regression"
      ],
      "metadata": {
        "id": "GaO34zgeXvsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "bc=datasets.load_breast_cancer()\n",
        "X,y=bc.data,bc.target\n",
        "\n",
        "n_samples, n_features=X.shape\n",
        "\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=1)\n",
        "\n",
        "\n",
        "# scale\n",
        "\n",
        "sc=StandardScaler()\n",
        "X_train=sc.fit_transform(X_train)\n",
        "X_test=sc.transform(X_test)\n",
        "\n",
        "X_train=torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test=torch.from_numpy(X_test.astype(np.float32))\n",
        "\n",
        "y_train=torch.from_numpy(y_train.astype(np.float32))\n",
        "y_test=torch.from_numpy(y_test.astype(np.float32))\n",
        "\n",
        "y_train=y_train.view(y_train.shape[0],1)\n",
        "y_test=y_test.view(y_test.shape[0],1)\n",
        "\n",
        "\n",
        "class LogisticRegression(nn.Module):\n",
        "  \n",
        "  def __init__(self, n_input_features):\n",
        "    super(LogisticRegression,self).__init__()\n",
        "    self.linear=nn.Linear(n_input_features,1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    y_predicted=torch.sigmoid(self.linear(x))\n",
        "    return y_predicted\n",
        "\n",
        "model=LogisticRegression(n_features)\n",
        "lr=0.01\n",
        "criterion=nn.BCELoss()\n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=lr)\n",
        "EPOCHS = 100\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  y_pred=model(X_train)\n",
        "  l=criterion(y_pred,y_train)\n",
        "  l.backward()\n",
        "  with torch.no_grad():\n",
        "    lo=criterion(model(X_test),y_test)\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "\n",
        "\n",
        "  if epoch % 5 == 0:\n",
        "    print(f'epoch: {epoch}; train_loss: {l.item():.4f}; val_loss: {lo.item():.4f};')\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "  y_predicted=model(X_test)\n",
        "  y_class=y_predicted.round()\n",
        "  acc=y_class.eq(y_test).sum() / float(y_test.shape[0])\n",
        "  print(f'accuracy: {acc.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcG4QI0v_VPS",
        "outputId": "cfbb8edd-91b6-48a6-b335-05f292b2a9e8"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0; train_loss: 0.6189; val_loss: 0.6197;\n",
            "epoch: 5; train_loss: 0.5483; val_loss: 0.5596;\n",
            "epoch: 10; train_loss: 0.4951; val_loss: 0.5135;\n",
            "epoch: 15; train_loss: 0.4537; val_loss: 0.4770;\n",
            "epoch: 20; train_loss: 0.4206; val_loss: 0.4474;\n",
            "epoch: 25; train_loss: 0.3935; val_loss: 0.4229;\n",
            "epoch: 30; train_loss: 0.3710; val_loss: 0.4023;\n",
            "epoch: 35; train_loss: 0.3519; val_loss: 0.3846;\n",
            "epoch: 40; train_loss: 0.3355; val_loss: 0.3693;\n",
            "epoch: 45; train_loss: 0.3213; val_loss: 0.3559;\n",
            "epoch: 50; train_loss: 0.3088; val_loss: 0.3440;\n",
            "epoch: 55; train_loss: 0.2977; val_loss: 0.3334;\n",
            "epoch: 60; train_loss: 0.2878; val_loss: 0.3238;\n",
            "epoch: 65; train_loss: 0.2789; val_loss: 0.3152;\n",
            "epoch: 70; train_loss: 0.2708; val_loss: 0.3073;\n",
            "epoch: 75; train_loss: 0.2635; val_loss: 0.3001;\n",
            "epoch: 80; train_loss: 0.2568; val_loss: 0.2934;\n",
            "epoch: 85; train_loss: 0.2506; val_loss: 0.2873;\n",
            "epoch: 90; train_loss: 0.2449; val_loss: 0.2816;\n",
            "epoch: 95; train_loss: 0.2397; val_loss: 0.2763;\n",
            "accuracy: 0.9474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DataLoading"
      ],
      "metadata": {
        "id": "TjVSa_DfnmPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class WineDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    #data loading\n",
        "    xy=np.loadtxt('/content/wine.csv',delimiter=\",\",dtype=np.float32,skiprows=1)\n",
        "\n",
        "    self.x=torch.from_numpy(xy[:,1:])\n",
        "    self.y=torch.from_numpy(xy[:,[0]]) #n_Samples,1\n",
        "    self.n_samples=xy.shape[0]\n",
        "  def __getitem__(self,index):\n",
        "    # dataset[0]\n",
        "    return self.x[index],self.y[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    #len(dataset)\n",
        "    return self.n_samples\n",
        "\n",
        "dataset=WineDataset()\n",
        "dataloader=DataLoader(dataset=dataset,batch_size=4,shuffle=True,num_workers=2)\n",
        "\n",
        "#training loop\n",
        "\n",
        "num_epochs=1\n",
        "total_samples=len(dataset)\n",
        "batch_size=4\n",
        "n_iterations=math.ceil(total_samples/batch_size)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for i,(inputs,labels) in enumerate(dataloader):\n",
        "    print(i)\n",
        "    print(inputs)\n",
        "    print(labels)"
      ],
      "metadata": {
        "id": "H_Rawi0EYS15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TorchVision Transform"
      ],
      "metadata": {
        "id": "a6LJ0Fets9FI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class WineDataset(Dataset):\n",
        "\n",
        "  def __init__(self,transform=None):\n",
        "    #data loading\n",
        "    xy=np.loadtxt('/content/wine.csv',delimiter=\",\",dtype=np.float32,skiprows=1)\n",
        "\n",
        "    self.x=xy[:,1:]\n",
        "    self.y=xy[:,[0]] #n_Samples,1\n",
        "    self.n_samples=xy.shape[0]\n",
        "    self.transform=transform\n",
        "  \n",
        "  def __getitem__(self,index):\n",
        "    # dataset[0]\n",
        "    sample= self.x[index],self.y[index]\n",
        "    if self.transform:\n",
        "      sample=self.transform(sample)\n",
        "    return sample\n",
        "\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    #len(dataset)\n",
        "    return self.n_samples\n",
        "\n",
        "\n",
        "class ToTensor:\n",
        "  def __call__(self,sample):\n",
        "    inputs,targets=sample\n",
        "    return torch.from_numpy(inputs),torch.from_numpy(targets)\n",
        "\n",
        "\n",
        "class MulTransform:\n",
        "  def __init__(self,factor):\n",
        "    self.factor=factor\n",
        "  \n",
        "  def __call__(self,sample):\n",
        "    inputs,target=sample\n",
        "    return inputs*self.factor,target*self.factor\n",
        "  \n",
        "dataset=WineDataset(transform=ToTensor())\n",
        "composed=torchvision.transforms.Compose([ToTensor(),MulTransform(2)])\n",
        "datanew=WineDataset(transform=composed)\n",
        "print(datanew[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jp0jepDVfJcR",
        "outputId": "061e9b15-2511-4b3f-d988-f5363a7b3772"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([2.8460e+01, 3.4200e+00, 4.8600e+00, 3.1200e+01, 2.5400e+02, 5.6000e+00,\n",
            "        6.1200e+00, 5.6000e-01, 4.5800e+00, 1.1280e+01, 2.0800e+00, 7.8400e+00,\n",
            "        2.1300e+03]), tensor([2.]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Softmax and Cross-Entropy"
      ],
      "metadata": {
        "id": "2TokZ22dwHbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "loss=nn.CrossEntropyLoss()\n",
        "\n",
        "Y=torch.tensor([0])\n",
        "y_pred_bad=torch.tensor([[24.1,43.0,1.0]])\n",
        "y_pred_good=torch.tensor([[43.0,0.1,1.0]])\n",
        "\n",
        "print(loss(y_pred_bad,Y).item())\n",
        "print(loss(y_pred_good,Y).item())\n",
        "\n",
        "_,pred=torch.max(y_pred_bad,1)\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btYZA-Louv5r",
        "outputId": "f1495f8f-fc44-4222-e38a-2145c34481ac"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18.899999618530273\n",
            "0.0\n",
            "tensor([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4S8SCxkMzZ-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNet(nn.Module):\n",
        "  \n",
        "  def __init__ (self,input_size,hidden_size,num_classes):\n",
        "    super(NeuralNet,self).__init__()\n",
        "    self.linear1=nn.Linear(input_size,hidden_size)\n",
        "    self.relu=nn.ReLU()\n",
        "    self.linear2=nn.Linear(hidden_size,num_classes)\n",
        "\n",
        "  def forward(self,x):\n",
        "    out=self.linear1(x)\n",
        "    out=self.relu(out)\n",
        "    out=self.linear2(out)\n",
        "    return out\n",
        "\n",
        "model=NeuralNet(input_size=28*28,hidden_size=5,num_classes=3)\n",
        "losses=nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "Uei238e9yQrN"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feed Forward"
      ],
      "metadata": {
        "id": "7av2SBpe3XGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device=torch.device('cpu')\n",
        "\n",
        "#hyper parameter\n",
        "input_size=784 #28*28\n",
        "hidden_size=100\n",
        "num_classes=10\n",
        "num_epochs=2\n",
        "batch_size=100\n",
        "learning_rate=0.001\n",
        "\n",
        "#data\n",
        "\n",
        "train_dataset=torchvision.datasets.MNIST(root='./data',train=True,transform=transforms.ToTensor(),download=True)\n",
        "test_dataset=torchvision.datasets.MNIST(root='./data',train=False,transform=transforms.ToTensor())\n",
        "\n",
        "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n",
        "\n",
        "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size)\n",
        "\n",
        "class NeuralNet(nn.Module):\n",
        "  \n",
        "  def __init__ (self,input_size,hidden_size,num_classes):\n",
        "    super(NeuralNet,self).__init__()\n",
        "    self.linear1=nn.Linear(input_size,hidden_size)\n",
        "    self.relu=nn.ReLU()\n",
        "    self.linear2=nn.Linear(hidden_size,num_classes)\n",
        "\n",
        "  def forward(self,x):\n",
        "    out=self.linear1(x)\n",
        "    out=self.relu(out)\n",
        "    out=self.linear2(out)\n",
        "    return out\n",
        "\n",
        "model=NeuralNet(input_size,hidden_size,num_classes)\n",
        "losses=nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
        "\n",
        "\n",
        "#training loop\n",
        "n_total_steps=len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "  for i,(images,labels) in enumerate(train_loader):\n",
        "    images=images.reshape(-1,28*28)\n",
        "    \n",
        "    output=model(images)\n",
        "    l=loss(output,labels)\n",
        "    l.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if(i+1%100==0):\n",
        "      print(f'Epoch: {epoch}; step: {i}; loss: {l.item()}')\n",
        "\n",
        "with torch.no_grad():\n",
        "  n_correct=0.0\n",
        "  n_samples=0.0\n",
        "  for images,labels in test_loader:\n",
        "    images=images.reshape(-1,28*28)\n",
        "    output=model(images)\n",
        "    _,pred=torch.max(output,1)\n",
        "    n_correct+=pred.eq(labels).sum().item()\n",
        "    n_samples+=labels.shape[0]\n",
        "\n",
        "print('accuracy: ',n_correct/n_samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvwvM7aVz4ku",
        "outputId": "82d49375-5aca-48da-aede-9fd0bef1f191"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy:  0.955\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "V0m_v1GC4kUg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}